# 6. AWS Lambda - Serverless Computing

## üéØ Objectifs

- Comprendre AWS Lambda et son utilisation
- Cr√©er des fonctions Lambda
- Traiter des donn√©es avec Lambda
- D√©clencher Lambda depuis S3
- Int√©grer Lambda avec d'autres services

## üìã Table des mati√®res

1. [Introduction √† Lambda](#introduction-√†-lambda)
2. [Cr√©er une fonction Lambda](#cr√©er-une-fonction-lambda)
3. [Traitement de donn√©es](#traitement-de-donn√©es)
4. [D√©clencheurs (Triggers)](#d√©clencheurs-triggers)
5. [Int√©gration avec autres services](#int√©gration-avec-autres-services)
6. [Bonnes pratiques](#bonnes-pratiques)

---

## Introduction √† Lambda

### Qu'est-ce qu'AWS Lambda ?

**AWS Lambda** = Service de calcul serverless

- **Serverless** : Pas de serveurs √† g√©rer
- **Event-driven** : D√©clench√© par √©v√©nements
- **Auto-scaling** : S'adapte automatiquement
- **Pay-per-use** : Payez seulement l'ex√©cution

### Cas d'usage pour Data Analyst

- **Traitement de fichiers** : Transformer fichiers upload√©s
- **ETL automatis√©** : D√©clencher des jobs Glue
- **Validation de donn√©es** : V√©rifier les donn√©es
- **Notifications** : Alerter sur √©v√©nements
- **Orchestration** : Coordonner plusieurs services

### Free Tier Lambda

**Gratuit √† vie :**
- 1 million de requ√™tes/mois
- 400 000 Go-secondes de temps de calcul/mois
- Au-del√† : facturation √† l'usage

**‚ö†Ô∏è Important :** Tr√®s g√©n√©reux pour la plupart des cas d'usage.

---

## Cr√©er une fonction Lambda

### √âtape 1 : Acc√©der √† Lambda

1. Console AWS ‚Üí Rechercher "Lambda"
2. Cliquer sur "AWS Lambda"
3. "Create function"

### √âtape 2 : Configuration de base

**Options :**

1. **Author from scratch** : Cr√©er depuis z√©ro
2. **Use a blueprint** : Utiliser un template
3. **Browse serverless app repository** : Applications pr√©-construites

**Configuration :**

1. **Function name** : `process-data-file`
2. **Runtime** : Python 3.11 (ou autre)
3. **Architecture** : x86_64 (par d√©faut)
4. **Permissions** : Cr√©er un nouveau r√¥le avec permissions de base

### √âtape 3 : Code de la fonction

**Exemple simple :**

```python
import json

def lambda_handler(event, context):
    """
    Fonction Lambda de base
    """
    # Traitement
    result = {
        'statusCode': 200,
        'body': json.dumps('Hello from Lambda!')
    }
    
    return result
```

**Tester la fonction :**

1. Cliquer sur "Test"
2. Cr√©er un √©v√©nement de test
3. Ex√©cuter
4. Voir les r√©sultats

---

## Traitement de donn√©es

### Exemple 1 : Traiter un fichier CSV

```python
import json
import csv
import boto3

s3 = boto3.client('s3')

def lambda_handler(event, context):
    # R√©cup√©rer le bucket et la cl√© depuis l'√©v√©nement
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']
    
    # T√©l√©charger le fichier
    response = s3.get_object(Bucket=bucket, Key=key)
    content = response['Body'].read().decode('utf-8')
    
    # Parser le CSV
    reader = csv.DictReader(content.splitlines())
    rows = list(reader)
    
    # Traiter les donn√©es
    processed = []
    for row in rows:
        processed.append({
            'id': row['id'],
            'name': row['name'].upper(),
            'email': row['email'].lower()
        })
    
    # Uploader le r√©sultat
    output_key = key.replace('raw/', 'processed/')
    s3.put_object(
        Bucket=bucket,
        Key=output_key,
        Body=json.dumps(processed)
    )
    
    return {
        'statusCode': 200,
        'body': f'Processed {len(processed)} rows'
    }
```

### Exemple 2 : Valider des donn√©es

```python
import json
import boto3

s3 = boto3.client('s3')

def lambda_handler(event, context):
    bucket = event['bucket']
    key = event['key']
    
    # T√©l√©charger le fichier
    response = s3.get_object(Bucket=bucket, Key=key)
    data = json.loads(response['Body'].read())
    
    # Valider
    errors = []
    for item in data:
        if 'email' not in item or '@' not in item['email']:
            errors.append(f"Invalid email for id {item.get('id')}")
        if 'age' in item and item['age'] < 0:
            errors.append(f"Invalid age for id {item.get('id')}")
    
    # Uploader le rapport
    if errors:
        s3.put_object(
            Bucket=bucket,
            Key=f'validation-errors/{key}',
            Body=json.dumps(errors)
        )
        return {
            'statusCode': 400,
            'body': f'Found {len(errors)} validation errors'
        }
    
    return {
        'statusCode': 200,
        'body': 'Validation passed'
    }
```

### Exemple 3 : D√©clencher un job Glue

```python
import boto3

glue = boto3.client('glue')

def lambda_handler(event, context):
    # Nom du job Glue √† ex√©cuter
    job_name = 'my-etl-job'
    
    # D√©clencher le job
    response = glue.start_job_run(
        JobName=job_name
    )
    
    return {
        'statusCode': 200,
        'body': f'Started Glue job: {response["JobRunId"]}'
    }
```

---

## D√©clencheurs (Triggers)

### D√©clencher depuis S3

**Configuration :**

1. Lambda ‚Üí Function ‚Üí "Add trigger"
2. Source : "S3"
3. Bucket : S√©lectionner le bucket
4. Event type : "All object create events" (ou sp√©cifique)
5. Prefix (optionnel) : `raw/` (seulement fichiers dans ce pr√©fixe)
6. Suffix (optionnel) : `.csv` (seulement fichiers CSV)

**R√©sultat :** Lambda s'ex√©cute automatiquement quand un fichier est upload√©.

### D√©clencher depuis EventBridge (schedule)

**Planifier une ex√©cution :**

1. Lambda ‚Üí Function ‚Üí "Add trigger"
2. Source : "EventBridge (CloudWatch Events)"
3. Rule : Cr√©er une nouvelle r√®gle
4. Schedule expression : `cron(0 2 * * ? *)` (tous les jours √† 2h)

**Exemple de cron :**
- `cron(0 2 * * ? *)` : Tous les jours √† 2h
- `cron(0 */6 * * ? *)` : Toutes les 6 heures
- `cron(0 0 ? * MON *)` : Tous les lundis √† minuit

### D√©clencher depuis API Gateway

**Cr√©er une API REST :**

1. API Gateway ‚Üí "Create API"
2. Type : REST API
3. Cr√©er une ressource et m√©thode
4. Int√©gration : Lambda Function
5. S√©lectionner la fonction Lambda

**R√©sultat :** Appel HTTP d√©clenche Lambda.

---

## Int√©gration avec autres services

### Lambda + S3

**Traitement automatique de fichiers :**

```python
import boto3

s3 = boto3.client('s3')

def lambda_handler(event, context):
    # √âv√©nement S3
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']
        
        # Traiter le fichier
        # ...
```

### Lambda + Glue

**D√©clencher un job Glue :**

```python
import boto3

glue = boto3.client('glue')

def lambda_handler(event, context):
    response = glue.start_job_run(
        JobName='my-etl-job',
        Arguments={
            '--input-path': 's3://bucket/raw/',
            '--output-path': 's3://bucket/processed/'
        }
    )
    return response
```

### Lambda + SNS (Notifications)

**Envoyer une notification :**

```python
import boto3
import json

sns = boto3.client('sns')

def lambda_handler(event, context):
    # Traitement...
    
    # Envoyer notification
    sns.publish(
        TopicArn='arn:aws:sns:region:account:topic',
        Message=json.dumps({
            'status': 'success',
            'message': 'Data processing completed'
        })
    )
    
    return {'statusCode': 200}
```

### Lambda + Step Functions

**Orchestrer plusieurs Lambdas :**

```json
{
  "Comment": "ETL Pipeline",
  "StartAt": "ProcessData",
  "States": {
    "ProcessData": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:region:account:function:process-data",
      "Next": "ValidateData"
    },
    "ValidateData": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:region:account:function:validate-data",
      "End": true
    }
  }
}
```

---

## Bonnes pratiques

### Performance

1. **Optimiser le code** pour r√©duire le temps d'ex√©cution
2. **Utiliser les bonnes m√©moires** (128 MB √† 10 GB)
3. **R√©utiliser les connexions** (boto3 clients)
4. **Utiliser des layers** pour d√©pendances communes

### Co√ªts

1. **Optimiser la dur√©e** d'ex√©cution
2. **Choisir la bonne m√©moire** (plus de m√©moire = plus rapide mais plus cher)
3. **√âviter les timeouts** inutiles
4. **Utiliser des r√©servations** si usage constant (pas dans Free Tier)

### S√©curit√©

1. **Utiliser IAM roles** pour permissions
2. **Ne pas hardcoder** les credentials
3. **Utiliser des variables d'environnement** pour configuration
4. **Activer VPC** si besoin d'acc√®s priv√©

### Gestion d'erreurs

```python
import json
import logging

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    try:
        # Traitement
        result = process_data(event)
        return {
            'statusCode': 200,
            'body': json.dumps(result)
        }
    except Exception as e:
        logger.error(f'Error: {str(e)}')
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }
```

---

## Exemples pratiques

### Exemple 1 : Pipeline ETL automatique

```python
import boto3
import json

s3 = boto3.client('s3')
glue = boto3.client('glue')

def lambda_handler(event, context):
    """
    D√©clenche un job Glue quand un fichier est upload√© dans S3
    """
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']
    
    # V√©rifier que c'est un fichier CSV
    if not key.endswith('.csv'):
        return {'statusCode': 200, 'body': 'Not a CSV file'}
    
    # D√©clencher le job Glue
    response = glue.start_job_run(
        JobName='csv-to-parquet-job',
        Arguments={
            '--input-path': f's3://{bucket}/{key}',
            '--output-path': f's3://{bucket}/processed/'
        }
    )
    
    return {
        'statusCode': 200,
        'body': f'Started Glue job: {response["JobRunId"]}'
    }
```

### Exemple 2 : Validation et notification

```python
import boto3
import json
import csv

s3 = boto3.client('s3')
sns = boto3.client('sns')

def lambda_handler(event, context):
    bucket = event['bucket']
    key = event['key']
    
    # T√©l√©charger et valider
    response = s3.get_object(Bucket=bucket, Key=key)
    content = response['Body'].read().decode('utf-8')
    reader = csv.DictReader(content.splitlines())
    
    errors = []
    for row in reader:
        if not row.get('email') or '@' not in row['email']:
            errors.append(f"Row {row.get('id')}: Invalid email")
    
    # Notification
    if errors:
        sns.publish(
            TopicArn='arn:aws:sns:region:account:alerts',
            Message=f'Validation failed: {len(errors)} errors found'
        )
    
    return {'statusCode': 200 if not errors else 400}
```

---

## üìä Points cl√©s √† retenir

1. **Lambda = Serverless** : Pas d'infrastructure √† g√©rer
2. **Free Tier : 1M requ√™tes/mois** : Tr√®s g√©n√©reux
3. **Event-driven** : D√©clench√© par √©v√©nements
4. **Int√©gration facile** : Avec tous les services AWS
5. **Pay-per-use** : Payez seulement l'ex√©cution

## üîó Prochain module

Passer au module [7. Projets pratiques](../07-projets/README.md) pour cr√©er des projets complets avec AWS.

