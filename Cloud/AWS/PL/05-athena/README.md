# 5. Amazon Athena - Zapytania SQL na S3

## ğŸ¯ Cele

- ZrozumieÄ‡ Amazon Athena i jego uÅ¼ycie
- TworzyÄ‡ tabele zewnÄ™trzne wskazujÄ…ce na S3
- WykonywaÄ‡ zapytania SQL na plikach S3
- OptymalizowaÄ‡ koszty i wydajnoÅ›Ä‡
- IntegrowaÄ‡ z Glue Data Catalog

## ğŸ“‹ Spis treÅ›ci

1. [Wprowadzenie do Athena](#wprowadzenie-do-athena)
2. [TworzyÄ‡ tabele zewnÄ™trzne](#tworzyÄ‡-tabele-zewnÄ™trzne)
3. [WykonywaÄ‡ zapytania](#wykonywaÄ‡-zapytania)
4. [Optymalizacja kosztÃ³w](#optymalizacja-kosztÃ³w)
5. [Integracja z Glue](#integracja-z-glue)
6. [Dobre praktyki](#dobre-praktyki)

---

## Wprowadzenie do Athena

### Czym jest Amazon Athena?

**Amazon Athena** = UsÅ‚uga zapytaÅ„ SQL serverless na S3

- **Serverless** : Brak infrastruktury do zarzÄ…dzania
- **Pay-per-query** : PÅ‚acisz tylko za uÅ¼ycie
- **Standard SQL** : Standardowa skÅ‚adnia SQL
- **BezpoÅ›rednio na S3** : Nie potrzeba Å‚adowaÄ‡ do bazy danych

### Przypadki uÅ¼ycia dla Data Analyst

- **Eksploracja danych** : Szybko analizowaÄ‡ pliki S3
- **Zapytania Data Lake** : Zapytania na data lake
- **Analizy ad-hoc** : Analizy jednorazowe
- **Analiza logÃ³w** : AnalizowaÄ‡ logi przechowywane w S3

### Free Tier Athena

**Darmowe na zawsze :**
- 10 GB danych przeskanowanych/miesiÄ…c
- Poza tym : 5$ za Terabajt przeskanowany

**âš ï¸ WaÅ¼ne :** Koszty zaleÅ¼Ä… od iloÅ›ci przeskanowanych danych. OptymalizowaÄ‡ zapytania aby zmniejszyÄ‡ koszty.

---

## TworzyÄ‡ tabele zewnÄ™trzne

### Metoda 1 : Przez edytor Athena

**Krok 1 : DostÄ™p do Athena**

1. Konsola AWS â†’ SzukaÄ‡ "Athena"
2. KliknÄ…Ä‡ "Amazon Athena"
3. Pierwsze uÅ¼ycie : SkonfigurowaÄ‡ wynik S3

**Krok 2 : SkonfigurowaÄ‡ wynik**

1. "Settings" â†’ "Manage"
2. "Query result location" : `s3://my-bucket/athena-results/`
3. "Save"

**Krok 3 : UtworzyÄ‡ tabelÄ™**

```sql
-- Tabela dla plikÃ³w CSV
CREATE EXTERNAL TABLE users (
    id INT,
    name STRING,
    email STRING,
    created_at TIMESTAMP
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
WITH SERDEPROPERTIES (
    'serialization.format' = ',',
    'field.delim' = ','
)
STORED AS TEXTFILE
LOCATION 's3://my-bucket/data/users/'
TBLPROPERTIES ('skip.header.line.count'='1');
```

### Metoda 2 : Przez Glue Data Catalog (zalecane)

**UÅ¼ywaÄ‡ tabel utworzonych przez Glue :**

1. Glue â†’ UtworzyÄ‡ crawler dla S3
2. Crawler automatycznie tworzy tabelÄ™
3. Athena uÅ¼ywa bezpoÅ›rednio tej tabeli

**Zalety :**
- Automatycznie wykryty schemat
- Nie potrzeba definiowaÄ‡ rÄ™cznie
- Wykorzystywane przez inne usÅ‚ugi

### ObsÅ‚ugiwane formaty

**CSV :**
```sql
CREATE EXTERNAL TABLE csv_data (
    col1 STRING,
    col2 INT
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
STORED AS TEXTFILE
LOCATION 's3://bucket/csv/';
```

**JSON :**
```sql
CREATE EXTERNAL TABLE json_data (
    id INT,
    name STRING
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
STORED AS TEXTFILE
LOCATION 's3://bucket/json/';
```

**Parquet (zalecane) :**
```sql
CREATE EXTERNAL TABLE parquet_data (
    id INT,
    name STRING,
    created_at TIMESTAMP
)
STORED AS PARQUET
LOCATION 's3://bucket/parquet/';
```

---

## WykonywaÄ‡ zapytania

### Podstawowe zapytania

**Prosty SELECT :**

```sql
SELECT * FROM users LIMIT 10;
```

**FiltrowaÄ‡ :**

```sql
SELECT 
    id,
    name,
    email
FROM users
WHERE created_at > DATE '2024-01-01'
ORDER BY created_at DESC;
```

**Agregacje :**

```sql
SELECT 
    DATE_TRUNC('month', created_at) AS month,
    COUNT(*) AS user_count,
    COUNT(DISTINCT email) AS unique_emails
FROM users
GROUP BY DATE_TRUNC('month', created_at)
ORDER BY month;
```

### Zaawansowane zapytania

**Funkcje okna :**

```sql
SELECT 
    id,
    name,
    created_at,
    ROW_NUMBER() OVER (PARTITION BY DATE_TRUNC('month', created_at) ORDER BY created_at) AS rank
FROM users;
```

**ZÅ‚Ä…czenia :**

```sql
SELECT 
    u.name,
    o.amount,
    o.created_at
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE o.created_at > DATE '2024-01-01';
```

### Zapytania na partycjach

**JeÅ›li dane sÄ… partycjonowane :**

```sql
-- Tabela partycjonowana wedÅ‚ug daty
CREATE EXTERNAL TABLE sales (
    id INT,
    product_id INT,
    amount DECIMAL(10,2)
)
PARTITIONED BY (sale_date DATE)
STORED AS PARQUET
LOCATION 's3://bucket/sales/';

-- DodaÄ‡ partycje
ALTER TABLE sales ADD PARTITION (sale_date='2024-01-01')
LOCATION 's3://bucket/sales/year=2024/month=01/day=01/';

-- Zapytanie z partycjÄ… (szybsze i taÅ„sze)
SELECT * FROM sales
WHERE sale_date = DATE '2024-01-01';
```

---

## Optymalizacja kosztÃ³w

### ZmniejszyÄ‡ przeskanowane dane

**1. UÅ¼ywaÄ‡ WHERE aby filtrowaÄ‡ wczeÅ›nie :**

```sql
-- âŒ ZÅ‚e : Skanuje wszystko potem filtruje
SELECT * FROM large_table
WHERE date = '2024-01-01';

-- âœ… Dobre : Filtruje od poczÄ…tku (jeÅ›li partycjonowane)
SELECT * FROM large_table
WHERE date = '2024-01-01';
```

**2. WybieraÄ‡ tylko potrzebne kolumny :**

```sql
-- âŒ ZÅ‚e : Skanuje wszystkie kolumny
SELECT * FROM large_table;

-- âœ… Dobre : Skanuje tylko potrzebne kolumny
SELECT id, name FROM large_table;
```

**3. UÅ¼ywaÄ‡ LIMIT :**

```sql
-- OgraniczyÄ‡ liczbÄ™ wynikÃ³w
SELECT * FROM large_table LIMIT 100;
```

### UÅ¼ywaÄ‡ Parquet

**Parquet jest bardziej efektywny niÅ¼ CSV :**

- **Kompresja** : Mniej przeskanowanych danych
- **Kolumny** : Skanuje tylko potrzebne kolumny
- **Zmniejszone koszty** : Do 90% redukcji

**KonwertowaÄ‡ CSV â†’ Parquet z Glue :**

```python
# Job Glue do konwersji
datasource = glueContext.create_dynamic_frame.from_catalog(
    database = "data_analyst_db",
    table_name = "csv_data"
)

glueContext.write_dynamic_frame.from_options(
    frame = datasource,
    connection_type = "s3",
    connection_options = {"path": "s3://bucket/parquet/"},
    format = "parquet"
)
```

### PartycjonowaÄ‡ dane

**PartycjonowaÄ‡ wedÅ‚ug daty (zalecane) :**

```
s3://bucket/data/
â”œâ”€â”€ year=2024/
â”‚   â”œâ”€â”€ month=01/
â”‚   â”‚   â”œâ”€â”€ day=01/
â”‚   â”‚   â””â”€â”€ day=02/
â”‚   â””â”€â”€ month=02/
```

**UtworzyÄ‡ tabelÄ™ partycjonowanÄ… :**

```sql
CREATE EXTERNAL TABLE partitioned_data (
    id INT,
    name STRING
)
PARTITIONED BY (year INT, month INT, day INT)
STORED AS PARQUET
LOCATION 's3://bucket/data/';
```

---

## Integracja z Glue

### UÅ¼ywaÄ‡ tabel Glue

**Tabele utworzone przez Glue sÄ… automatycznie dostÄ™pne w Athena :**

1. Glue â†’ Crawler tworzy tabelÄ™
2. Athena â†’ "Tables" â†’ ZobaczyÄ‡ wszystkie tabele Glue
3. UÅ¼ywaÄ‡ bezpoÅ›rednio w zapytaniach

**Zalety :**
- Automatyczny schemat
- Brak rÄ™cznej definicji
- Automatyczna synchronizacja

### AktualizowaÄ‡ partycje

**JeÅ›li dodane nowe dane :**

```sql
-- AktualizowaÄ‡ partycje
MSCK REPAIR TABLE sales;

-- Lub dodaÄ‡ rÄ™cznie
ALTER TABLE sales ADD PARTITION (sale_date='2024-01-02')
LOCATION 's3://bucket/sales/year=2024/month=01/day=02/';
```

---

## Dobre praktyki

### WydajnoÅ›Ä‡

1. **UÅ¼ywaÄ‡ Parquet** zamiast CSV
2. **PartycjonowaÄ‡ dane** wedÅ‚ug daty/kategorii
3. **WybieraÄ‡ tylko potrzebne kolumny**
4. **FiltrowaÄ‡ wczeÅ›nie** z WHERE
5. **UÅ¼ywaÄ‡ LIMIT** do eksploracji

### Koszty

1. **MonitorowaÄ‡ przeskanowane dane** w wynikach
2. **OptymalizowaÄ‡ zapytania** aby zmniejszyÄ‡ skanowanie
3. **UÅ¼ywaÄ‡ Parquet** do kompresji
4. **PartycjonowaÄ‡** aby zmniejszyÄ‡ skanowanie
5. **BuforowaÄ‡** czÄ™ste wyniki

### Organizacja

1. **OrganizowaÄ‡ S3** ze spÃ³jnymi prefiksami
2. **NazywaÄ‡ tabele** jasno
3. **DokumentowaÄ‡ schematy**
4. **UÅ¼ywaÄ‡ baz danych** do organizacji

---

## PrzykÅ‚ady praktyczne

### PrzykÅ‚ad 1 : AnalizowaÄ‡ logi

```sql
-- Tabela dla logÃ³w
CREATE EXTERNAL TABLE logs (
    timestamp TIMESTAMP,
    level STRING,
    message STRING,
    user_id INT
)
PARTITIONED BY (date DATE)
STORED AS TEXTFILE
LOCATION 's3://bucket/logs/';

-- Zapytanie : BÅ‚Ä™dy na dzieÅ„
SELECT 
    date,
    COUNT(*) AS error_count
FROM logs
WHERE level = 'ERROR'
GROUP BY date
ORDER BY date DESC;
```

### PrzykÅ‚ad 2 : AnalizowaÄ‡ dane CSV

```sql
-- Tabela CSV
CREATE EXTERNAL TABLE sales_csv (
    id INT,
    product_id INT,
    amount DECIMAL(10,2),
    sale_date DATE
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
STORED AS TEXTFILE
LOCATION 's3://bucket/sales/csv/'
TBLPROPERTIES ('skip.header.line.count'='1');

-- Analiza : SprzedaÅ¼ na miesiÄ…c
SELECT 
    DATE_TRUNC('month', sale_date) AS month,
    SUM(amount) AS total_sales,
    COUNT(*) AS transaction_count
FROM sales_csv
GROUP BY DATE_TRUNC('month', sale_date)
ORDER BY month;
```

### PrzykÅ‚ad 3 : ZÅ‚Ä…czenie wielu tabel

```sql
-- AnalizowaÄ‡ z zÅ‚Ä…czeniami
SELECT 
    p.name AS product_name,
    c.name AS category_name,
    SUM(s.amount) AS total_sales
FROM sales s
JOIN products p ON s.product_id = p.id
JOIN categories c ON p.category_id = c.id
WHERE s.sale_date >= DATE '2024-01-01'
GROUP BY p.name, c.name
ORDER BY total_sales DESC
LIMIT 10;
```

---

## ğŸ“Š Kluczowe punkty do zapamiÄ™tania

1. **Athena = SQL serverless** na plikach S3
2. **Free Tier : 10 GB/miesiÄ…c** przeskanowanych danych
3. **Parquet** = najbardziej efektywny format
4. **PartycjonowaÄ‡** = zmniejszyÄ‡ koszty
5. **Integracja Glue** = automatyczne schematy

## ğŸ”— NastÄ™pny moduÅ‚

PrzejdÅº do moduÅ‚u [6. AWS Lambda - Serverless Computing](../06-lambda/README.md), aby nauczyÄ‡ siÄ™ automatyzowaÄ‡ przetwarzanie danych.

