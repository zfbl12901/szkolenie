# 2. Podstawowe koncepcje Airflow

## ğŸ¯ Cele

- ZrozumieÄ‡ DAGi (Directed Acyclic Graphs)
- OpanowaÄ‡ zadania i zaleÅ¼noÅ›ci
- ZrozumieÄ‡ harmonogramowanie
- UÅ¼ywaÄ‡ zmiennych i poÅ‚Ä…czeÅ„
- ZarzÄ…dzaÄ‡ wykonaniami

## ğŸ“‹ Spis treÅ›ci

1. [DAGi (Directed Acyclic Graphs)](#dagi-directed-acyclic-graphs)
2. [Zadania i zaleÅ¼noÅ›ci](#zadania-i-zaleÅ¼noÅ›ci)
3. [Harmonogramowanie](#harmonogramowanie)
4. [Zmienne i PoÅ‚Ä…czenia](#zmienne-i-poÅ‚Ä…czenia)
5. [Wykonania i stany](#wykonania-i-stany)

---

## DAGi (Directed Acyclic Graphs)

### Czym jest DAG?

**DAG** = Graf skierowany acykliczny

- **Skierowany** : Zadania majÄ… kierunek (zaleÅ¼noÅ›ci)
- **Acykliczny** : Brak pÄ™tli (brak zaleÅ¼noÅ›ci cyklicznych)
- **Graf** : Wizualna reprezentacja przepÅ‚ywÃ³w pracy

### Struktura DAGa

```python
from airflow import DAG
from datetime import datetime, timedelta

# Argumenty domyÅ›lne
default_args = {
    'owner': 'data_analyst',
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# UtworzyÄ‡ DAG
dag = DAG(
    'my_dag',
    default_args=default_args,
    description='Opis DAGa',
    schedule_interval='@daily',  # CzÄ™stotliwoÅ›Ä‡ wykonania
    start_date=datetime(2024, 1, 1),
    catchup=False,  # Nie wykonywaÄ‡ przeszÅ‚ych runÃ³w
    tags=['example'],
)
```

### WÅ‚aÅ›ciwoÅ›ci DAGa

**Unikalne ID :**
- Musi byÄ‡ unikalne w instalacji Airflow
- UÅ¼ywane do identyfikacji DAGa

**Schedule interval :**
- `@daily` : Codziennie
- `@hourly` : Co godzinÄ™
- `timedelta(days=1)` : Codziennie
- `'0 2 * * *'` : WyraÅ¼enie cron (codziennie o 2h)
- `None` : Tylko rÄ™czne wyzwalanie

**Start date :**
- Data rozpoczÄ™cia harmonogramowania
- Format : `datetime(rok, miesiÄ…c, dzieÅ„)`

**Catchup :**
- `True` : Wykonuje brakujÄ…ce runy od start_date
- `False` : Wykonuje tylko przyszÅ‚e runy

---

## Zadania i zaleÅ¼noÅ›ci

### Czym jest Zadanie?

**Zadanie** = Pojedynczy krok w DAGu

- **Operator** : Typ zadania (Python, Bash, SQL, itp.)
- **Unikalne ID** : Identyfikator w DAGu
- **ZaleÅ¼noÅ›ci** : Relacje z innymi zadaniami

### Typy operatorÃ³w

**BashOperator :**
```python
from airflow.operators.bash import BashOperator

task = BashOperator(
    task_id='bash_task',
    bash_command='echo "Hello"',
    dag=dag,
)
```

**PythonOperator :**
```python
from airflow.operators.python import PythonOperator

def my_function():
    print("Hello from Python")

task = PythonOperator(
    task_id='python_task',
    python_callable=my_function,
    dag=dag,
)
```

### ZdefiniowaÄ‡ zaleÅ¼noÅ›ci

**Metoda 1 : Operator >>**

```python
# t1 wykonuje siÄ™ przed t2
t1 >> t2

# Wiele zaleÅ¼noÅ›ci
t1 >> [t2, t3] >> t4
```

**Metoda 2 : set_upstream / set_downstream**

```python
# t1 wykonuje siÄ™ przed t2
t1.set_downstream(t2)
# lub
t2.set_upstream(t1)
```

**Metoda 3 : bitshift**

```python
# t1 >> t2 jest rÃ³wnowaÅ¼ne
t1 >> t2
```

### PrzykÅ‚ad zaleÅ¼noÅ›ci

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

dag = DAG('dependencies_example', start_date=datetime(2024, 1, 1))

# Zadania
extract = BashOperator(task_id='extract', bash_command='echo extract', dag=dag)
transform = BashOperator(task_id='transform', bash_command='echo transform', dag=dag)
load = BashOperator(task_id='load', bash_command='echo load', dag=dag)
validate = BashOperator(task_id='validate', bash_command='echo validate', dag=dag)

# ZaleÅ¼noÅ›ci
extract >> transform >> [load, validate]
```

---

## Harmonogramowanie

### Schedule Interval

**CzÄ™ste wyraÅ¼enia :**

```python
# Codziennie o pÃ³Å‚nocy
schedule_interval='@daily'
# lub
schedule_interval=timedelta(days=1)

# Co godzinÄ™
schedule_interval='@hourly'
# lub
schedule_interval=timedelta(hours=1)

# Co tydzieÅ„
schedule_interval='@weekly'

# WyraÅ¼enie cron
schedule_interval='0 2 * * *'  # Codziennie o 2h
schedule_interval='0 */6 * * *'  # Co 6 godzin
schedule_interval='0 0 * * MON'  # W kaÅ¼dy poniedziaÅ‚ek o pÃ³Å‚nocy
```

### Start Date i Execution Date

**Start Date :**
- Data rozpoczÄ™cia harmonogramowania
- Format : `datetime(2024, 1, 1)`

**Execution Date :**
- Logiczna data wykonania
- Format : `YYYY-MM-DDTHH:MM:SS`

**PrzykÅ‚ad :**
```python
dag = DAG(
    'scheduled_dag',
    schedule_interval='@daily',
    start_date=datetime(2024, 1, 1),
    catchup=False,
)
```

### Catchup

**Catchup = True :**
- Wykonuje wszystkie brakujÄ…ce runy od start_date
- MoÅ¼e utworzyÄ‡ wiele runÃ³w

**Catchup = False :**
- Wykonuje tylko przyszÅ‚e runy
- Zalecane dla wiÄ™kszoÅ›ci przypadkÃ³w

---

## Zmienne i PoÅ‚Ä…czenia

### Zmienne

**Zmienne = Konfiguracja globalna**

**UtworzyÄ‡ zmiennÄ… :**

```bash
# Przez CLI
airflow variables set my_key "my_value"

# Przez interfejs web
# Admin â†’ Variables â†’ Add
```

**UÅ¼ywaÄ‡ zmiennej :**

```python
from airflow.models import Variable

# PobraÄ‡ zmiennÄ…
my_value = Variable.get("my_key")
my_value_default = Variable.get("my_key", default_var="default")

# W szablonie
# {{ var.value.my_key }}
```

**PrzykÅ‚ad :**

```python
from airflow import DAG
from airflow.models import Variable
from airflow.operators.python import PythonOperator
from datetime import datetime

dag = DAG('variables_example', start_date=datetime(2024, 1, 1))

def use_variable():
    api_key = Variable.get("api_key")
    print(f"API Key: {api_key}")

task = PythonOperator(
    task_id='use_variable',
    python_callable=use_variable,
    dag=dag,
)
```

### PoÅ‚Ä…czenia

**PoÅ‚Ä…czenia = Informacje o poÅ‚Ä…czeniu**

**UtworzyÄ‡ poÅ‚Ä…czenie :**

```bash
# Przez CLI
airflow connections add 'my_postgres' \
    --conn-type 'postgres' \
    --conn-host 'localhost' \
    --conn-login 'user' \
    --conn-password 'password' \
    --conn-port 5432 \
    --conn-schema 'mydb'
```

**UÅ¼ywaÄ‡ poÅ‚Ä…czenia :**

```python
from airflow.hooks.base import BaseHook

# PobraÄ‡ poÅ‚Ä…czenie
conn = BaseHook.get_connection('my_postgres')
print(f"Host: {conn.host}")
print(f"Login: {conn.login}")
print(f"Password: {conn.password}")
```

---

## Wykonania i stany

### Stany zadaÅ„

- **None** : Jeszcze nie wykonane
- **Scheduled** : Zaplanowane
- **Queued** : W kolejce
- **Running** : W trakcie wykonania
- **Success** : ZakoÅ„czone sukcesem
- **Failed** : Nieudane
- **Skipped** : PominiÄ™te
- **Retry** : Ponawianie
- **Up for retry** : Gotowe do ponowienia

### Stany DAGÃ³w

- **Running** : W trakcie wykonania
- **Success** : Wszystkie zadania zakoÅ„czone sukcesem
- **Failed** : Przynajmniej jedno zadanie nieudane

### ZarzÄ…dzaÄ‡ wykonaniami

**Przez interfejs web :**
- WidzieÄ‡ stan wykonania
- UruchomiÄ‡ ponownie zadanie
- OznaczyÄ‡ jako sukces/niepowodzenie
- WidzieÄ‡ logi

**Przez CLI :**

```bash
# ListowaÄ‡ runy
airflow dags list-runs -d my_dag

# WyzwoliÄ‡ DAG
airflow dags trigger my_dag

# OznaczyÄ‡ zadanie jako sukces
airflow tasks clear my_dag task_id -s 2024-01-01
```

---

## PrzykÅ‚ady praktyczne

### PrzykÅ‚ad 1 : DAG ze zmiennymi

```python
from airflow import DAG
from airflow.models import Variable
from airflow.operators.python import PythonOperator
from datetime import datetime

dag = DAG('variables_dag', start_date=datetime(2024, 1, 1))

def process_data():
    # PobraÄ‡ zmienne
    input_path = Variable.get("input_path")
    output_path = Variable.get("output_path")
    
    print(f"Processing: {input_path} -> {output_path}")

task = PythonOperator(
    task_id='process',
    python_callable=process_data,
    dag=dag,
)
```

### PrzykÅ‚ad 2 : DAG z poÅ‚Ä…czeniem

```python
from airflow import DAG
from airflow.hooks.postgres import PostgresHook
from airflow.operators.python import PythonOperator
from datetime import datetime

dag = DAG('connection_dag', start_date=datetime(2024, 1, 1))

def query_database():
    # UÅ¼ywaÄ‡ poÅ‚Ä…czenia PostgreSQL
    hook = PostgresHook(postgres_conn_id='my_postgres')
    records = hook.get_records("SELECT * FROM users LIMIT 10")
    print(records)

task = PythonOperator(
    task_id='query',
    python_callable=query_database,
    dag=dag,
)
```

---

## ğŸ“Š Kluczowe punkty do zapamiÄ™tania

1. **DAGi** definiujÄ… workflows
2. **Zadania** to pojedyncze kroki
3. **ZaleÅ¼noÅ›ci** definiujÄ… kolejnoÅ›Ä‡ wykonania
4. **Harmonogramowanie** planuje wykonania
5. **Zmienne i PoÅ‚Ä…czenia** dla konfiguracji

## ğŸ”— NastÄ™pny moduÅ‚

PrzejdÅº do moduÅ‚u [3. Operatory](../03-operators/README.md), aby nauczyÄ‡ siÄ™ uÅ¼ywaÄ‡ rÃ³Å¼nych operatorÃ³w Airflow.

